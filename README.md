# Compilation of Papers on LLM Alignment based on Socio-Cultural Contexts

## Introduction
This repository is dedicated to the collection of research papers on LLM alignment based on socio-cultural contexts, particularly for low resource languages beyond English. We mainly focus on Indonesian language as target language to evaluate on, but the repository also lists papers based on English and South East Asia (SEA) benchmark datasets as scientific references.

### Purpose
This repository aims to:
- Serve as a centralized resource not only for internal BRIN researchers, but also researchers from the other institutions, students, and LLM enthusiasts/practitioners.
- Enhance understanding of how to create a good taxonomy for alignment benchmark dataset.
- Enhance understanding of how LLMs aligns with various human values and cultural contexts.
- Better understand the research gap in LLM alignment for low resource language, particularly Indonesian language.
- Stimulate discussion and promote further research in this critical area of LLM alignment and benchmark dataset creation.

## Contents
- [Papers](#papers)
- [Conferences and Workshops](#conferences-and-workshops)
- [How to Contribute](#how-to-contribute)

## Papers
Here, you'll find a curated list of academic papers, articles, and publications that explore the intersections of AI, Language Models, and cultural value alignment.

### Taxonomy: Gender bias, Cultural dimension
- (11-2023) [CDEval: A Benchmark for Measuring the Cultural Dimensions of Large Language Models](https://arxiv.org/abs/2311.16421)

### Cultural alignment
- (2-2024) [Investigating Cultural Alignment of Large Language Models](https://arxiv.org/abs/2402.13231)
- (2-2024) [CIDAR: Culturally Relevant Instruction Dataset For Arabic](https://arxiv.org/abs/2402.03177)
- (8-2023) [Cultural Alignment in Large Language Models: An Explanatory Analysis Based on Hofstede's Cultural Dimensions](https://arxiv.org/abs/2309.12342)

### General: LLM Bias
- (5-2023) [Having Beer after Prayer? Measuring Cultural Bias in Large Language Models](https://arxiv.org/abs/2305.14456)
- (4-2023) [Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language Models](https://arxiv.org/pdf/2304.03738.pdf)
- (3-2034) [Whose Opinions Do Language Models Reflect?](https://arxiv.org/pdf/2303.17548.pdf)
- (2021) [Gender bias, social bias, and representation in Bollywood and Hollywood](https://www.sciencedirect.com/science/article/pii/S266638992100283X)
- (2020) [UNQOVERing Stereotypical Biases via Underspecified Questions](https://arxiv.org/abs/2010.02428)

### National Bias
- (8-2023  [Unmasking Nationality Bias: A Study of Human Perception of Nationalities in AI-Generated Articles] (https://arxiv.org/abs/2308.04346)
- (2-2023) [Nationality Bias in Text Generation](https://arxiv.org/abs/2302.02463)

### Cultural Bias
- (3-2023) [Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study](https://arxiv.org/abs/2303.17466)
- (3-2023) [Probing Pre-Trained Language Models for Cross-Cultural Differences in Values](https://arxiv.org/abs/2203.13722)

### Alignment and Preference tuning

- (8-2023) [Group Preference Optimization: Few-Shot Alignment of Large Language Models](https://arxiv.org/abs/2310.11523)
- (5-2023) [Training Socially Aligned Language Models on Simulated Social Interactions](https://arxiv.org/abs/2305.16960)
- (4-2023) [In Conversation with Artificial Intelligence: Aligning Language Models with Human Values](https://link.springer.com/article/10.1007/s13347-023-00606-x)
- (2020) [Artificial Intelligence, Values, and Alignment](https://link.springer.com/article/10.1007/s11023-020-09539-2)

### 2022
- [Cultural Incongruencies in Artificial Intelligence](https://arxiv.org/pdf/2211.13069.pdf)
- [The Myth of Culturally Agnostic AI Models](https://arxiv.org/ftp/arxiv/papers/2211/2211.15271.pdf)
- [French CrowS-Pairs: Extending a challenge dataset for measuring social bias in masked language models to a language other than English](https://aclanthology.org/2022.acl-long.583/)

### Word Embedding bias
- [Assessing Social and Intersectional Biases in Contextualized Word Representations](https://arxiv.org/abs/1911.01485)

## Conferences and Workshops
Find information on relevant conferences and workshops focusing on cultural alignment in AI:

- [Cultures in AI/AI in Culture - A NeurIPS 2022 Workshop](https://ai-cultures.github.io/) - December, NeurIPS 2022.
- [Socially Responsible Language Modelling Research](https://solar-neurips.github.io/) - December, NeurIPS 2023.
- [Proceedings of the First Workshop on Cross-Cultural Considerations in NLP (C3NLP)](https://aclanthology.org/volumes/2023.c3nlp-1/) - May, Association for Computational Linguistics 2023.

## How to Contribute
We welcome contributions! You can help by:
- **Adding New Resources**: Share new findings or resources.
- **Updating Existing Entries**: Ensure information is up-to-date and accurate.
- **Enhancing Organization**: Offer suggestions for a more user-friendly experience or a better structure.

To contribute:
1. Fork the repository.
2. Make your changes.
3. Submit a pull request with a detailed description of your changes.

### Contact
Have questions or suggestions? Feel free to [contact us](mailto:iftitahu.nimah@brin.go.id).
